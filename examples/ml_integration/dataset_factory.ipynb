{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "![Dataset Factory Hero](assets/dataset_hero.png)\n",
                "\n",
                "# üìÅ Bulk Dataset Factory: Beyond the Memory Wall ü§ñ\n",
                "\n",
                "**Objective**: Master the transition from \"Single-Protein\" bioinformatics to \"Tensor-Driven\" AI research.\n",
                "\n",
                "### üß† The Educational Mindset Shift\n",
                "Traditional structural biology focuses on the **PDB File**‚Äîa static, human-readable text record. Modern AI (like AlphaFold-3 or ESM-Fold) requires a **Tensor**‚Äîa massive, multi-dimensional array of numbers. \n",
                "\n",
                "In this lab, we break through the **\"Memory Wall\"**: the bottleneck where AI models spend more time *reading files* than actually *learning biology*.\n",
                "\n",
                "**We will cover:**\n",
                "1. **Vectorized Generation**: Producing 10,000 unique structures in milliseconds.\n",
                "2. **The Tensor Envelope**: Visualizing the structural diversity of your dataset.\n",
                "3. **Zero-Copy NPZ Pipelines**: Feeding binary data directly into high-performance GPUs.\n",
                "4. **PyTorch Integration**: Building a production-ready `DataLoader`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "cellView": "form"
            },
            "outputs": [],
            "source": [
                "# @title Setup & Installation { display-mode: \"form\" }\n",
                "import os\n",
                "import sys\n",
                "from pathlib import Path\n",
                "\n",
                "# Ensure the local synth_pdb source code is prioritized if running from the repo\n",
                "try:\n",
                "    current_path = Path(\".\").resolve()\n",
                "    repo_root = current_path.parent.parent \n",
                "    if (repo_root / \"synth_pdb\").exists():\n",
                "        if str(repo_root) not in sys.path:\n",
                "            sys.path.insert(0, str(repo_root))\n",
                "            print(f\"üìå Added local library to path: {repo_root}\")\n",
                "except Exception:\n",
                "    pass\n",
                "\n",
                "if 'google.colab' in str(get_ipython()):\n",
                "    if not os.path.exists(\"installed.marker\"):\n",
                "        print(\"Running on Google Colab. Installing dependencies...\")\n",
                "        get_ipython().run_line_magic('pip', 'install synth-pdb torch numpy matplotlib py3Dmol')\n",
                "        \n",
                "        with open(\"installed.marker\", \"w\") as f:\n",
                "            f.write(\"done\")\n",
                "        \n",
                "        print(\"üîÑ Installation complete. KERNEL RESTARTING AUTOMATICALLY...\")\n",
                "        print(\"‚ö†Ô∏è Please wait 10 seconds, then Run All Cells again.\")\n",
                "        os.kill(os.getpid(), 9)\n",
                "    else:\n",
                "        print(\"‚úÖ Dependencies Ready.\")\n",
                "else:\n",
                "    import synth_pdb\n",
                "    print(f\"‚úÖ Running locally. Using synth-pdb version: {synth_pdb.__version__} from {synth_pdb.__file__}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "import time\n",
                "import torch\n",
                "from torch.utils.data import Dataset, DataLoader\n",
                "import matplotlib.pyplot as plt\n",
                "import py3Dmol\n",
                "from synth_pdb.batch_generator import BatchedGenerator, BatchedPeptide\n",
                "\n",
                "print(\"Libraries Loaded. Accelerating with PyTorch! üöÄ\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. High-Speed Generation: 10,000 Structures\n",
                "\n",
                "We leverage **Numba-optimized vectorization**. Instead of generating one CA atom at a time, we treat the entire batch as a single 3D tensor operation."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "n_samples = 10000\n",
                "# FIX: Use explicit hyphenation for the whole sequence to avoid 'METALA' merging errors\n",
                "sequence = \"-\".join([\"ALA-GLY-SER-LEU-VAL-ILE-MET\"] * 4) # 28 residues\n",
                "\n",
                "print(f\"üöÄ Generating {n_samples} structures...\")\n",
                "start = time.time()\n",
                "\n",
                "generator = BatchedGenerator(sequence, n_batch=n_samples, full_atom=False)\n",
                "batch = generator.generate_batch(drift=5.0)\n",
                "\n",
                "elapsed = time.time() - start\n",
                "print(f\"‚úÖ Done! {n_samples} structures generated in {elapsed:.3f}s\")\n",
                "print(f\"Throughput: {n_samples/elapsed:.0f} structures/sec\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Visualizing Structural Diversity (Statistical Plot)\n",
                "\n",
                "A dataset is only as good as its **diversity**. If all 10,000 structures look the same, the model learns nothing. Let's visualize the \"Atomic Variance\" across our batch."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Calculate the variance of CA positions across the batch\n",
                "variance = np.var(batch.coords, axis=0).mean(axis=1)\n",
                "\n",
                "plt.figure(figsize=(10, 5))\n",
                "plt.plot(variance, color='#667eea', linewidth=3, label=\"Positional Variance\")\n",
                "plt.fill_between(range(len(variance)), variance, alpha=0.2, color='#667eea')\n",
                "plt.title(\"The Entropy Profile: Data Diversity across the Chain\")\n",
                "plt.xlabel(\"Residue Number\")\n",
                "plt.ylabel(\"Variance (√Ö¬≤)\")\n",
                "plt.grid(alpha=0.3)\n",
                "plt.legend()\n",
                "plt.show()\n",
                "\n",
                "print(\"Educational Insight: Notice how variance typically increases at the 'tail' of the peptide?\")\n",
                "print(\"This is the 'Propagating Error' of structural drift‚Äîa key feature for generating negative samples.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Interactive 3D Ensemble View\n",
                "\n",
                "Let's overlay the first 5 structures in the batch to see the \"Envelope\" of noise we've created."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "try:\n",
                "    view = py3Dmol.view(width=800, height=400)\n",
                "    view.setBackgroundColor(\"#fdfdfd\")\n",
                "    colors = [\"#ff9999\", \"#66b3ff\", \"#99ff99\", \"#ffcc99\", \"#c2c2f0\"]\n",
                "\n",
                "    for i in range(5):\n",
                "        # 1. Clean and mask coordinates with strict zero-tolerance\n",
                "        c = batch.coords[i].copy()\n",
                "        mask = np.any(np.abs(c) > 1e-4, axis=1) # Strip zeros and ghost atoms\n",
                "        c_clean = c[mask]\n",
                "        \n",
                "        if len(c_clean) == 0: continue\n",
                "        \n",
                "        # 2. Individual Centering (Per-Model Anchor)\n",
                "        # Using CA centroid for much better stability than min/max\n",
                "        ca_idxs = [j for j, name in enumerate(batch.atom_names) if name == \"CA\"]\n",
                "        valid_ca = [idx for idx in ca_idxs if mask[idx]]\n",
                "        if valid_ca:\n",
                "            center = c[valid_ca].mean(axis=0)\n",
                "        else:\n",
                "            center = c_clean.mean(axis=0)\n",
                "            \n",
                "        c_centered = c_clean - center\n",
                "        \n",
                "        p_tmp = BatchedPeptide(\n",
                "            c_centered[np.newaxis, ...], \n",
                "            batch.sequence, \n",
                "            np.array(batch.atom_names)[mask].tolist(), \n",
                "            np.array(batch.residue_indices)[mask].tolist()\n",
                "        )\n",
                "        \n",
                "        view.addModel(p_tmp.to_pdb(0), 'pdb')\n",
                "        # HIGH-VISIBILITY STYLE: Large Spheres (radius 0.3) + Thick Sticks\n",
                "        view.setStyle({'model': i}, {\n",
                "            \"cartoon\": {\"color\": colors[i], \"opacity\": 0.5}, \n",
                "            \"stick\": {\"color\": colors[i], \"radius\": 0.3}, \n",
                "            \"sphere\": {\"color\": colors[i], \"scale\": 0.3}\n",
                "        })\n",
                "\n",
                "    # 3. Aggressive manual zoom targeting model 0 to ensure viewport is filled\n",
                "    view.zoomTo({'model': 0})\n",
                "    view.zoom(2.0)\n",
                "    view.center()\n",
                "    view.show()\n",
                "    \n",
                "    # Diagnostic Info to prove sanity\n",
                "    print(f\"‚úÖ Ensemble Visualized with PDB Column-Shift Guard.\")\n",
                "    print(f\"Residue 1 Name: '{batch.sequence[0]}' | Residue 7 Name: '{batch.sequence[6]}'\")\n",
                "    \n",
                "except Exception as e:\n",
                "    print(f\"3D Viewer Error: {e}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Binary Export (NPZ) vs. Legacy Text (PDB)\n",
                "\n",
                "Why save to NPZ? It's not just about size; it's about **Zero-Copy loading**."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "os.makedirs(\"dataset_factory\", exist_ok=True)\n",
                "dataset_path = \"dataset_factory/batch_001.npz\"\n",
                "\n",
                "print(\"Saving to compressed NPZ...\")\n",
                "np.savez_compressed(\n",
                "    dataset_path,\n",
                "    coords=batch.coords,\n",
                "    sequence=np.array([sequence] * n_samples)\n",
                ")\n",
                "\n",
                "# Benchmark Loading\n",
                "start_npz = time.time()\n",
                "tensor_npz = torch.from_numpy(np.load(dataset_path)['coords'])\n",
                "npz_time = time.time() - start_npz\n",
                "\n",
                "print(f\"‚úÖ NPZ Load (10k samples): {npz_time:.4f}s\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Production PyTorch DataLoader\n",
                "\n",
                "The final piece of the pipeline is the `DataLoader`, which handles batching, shuffling, and multi-threaded loading."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class SyntheticProteinDataset(Dataset):\n",
                "    def __init__(self, npz_path):\n",
                "        data = np.load(npz_path)\n",
                "        self.coords = torch.from_numpy(data['coords']).float()\n",
                "        \n",
                "    def __len__(self):\n",
                "        return len(self.coords)\n",
                "        \n",
                "    def __getitem__(self, idx):\n",
                "        return self.coords[idx]\n",
                "\n",
                "ds = SyntheticProteinDataset(dataset_path)\n",
                "loader = DataLoader(ds, batch_size=64, shuffle=True)\n",
                "\n",
                "sample_batch = next(iter(loader))\n",
                "print(f\"Success! Batch Shape: {sample_batch.shape} (Ready for Neural Network training)\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### üèÜ Next Steps\n",
                "1. Modify the `drift` parameter in Section 1. How does it change the **Variance Plot** in Section 2?\n",
                "2. Try generating a batch with `full_atom=True`. How does it affect the NPZ file size?\n",
                "\n",
                "Mastering the **Data Plane** is 80% of successful AI engineering. Now go build some biology! üß¨ü§ñ"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.2"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}