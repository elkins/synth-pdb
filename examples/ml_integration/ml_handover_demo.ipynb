{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "![ML Handover Hero](assets/hero.png)\n",
                "\n",
                "# ML Integration: Data Factory Flow ü§ñ"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "This notebook demonstrates how to use `synth-pdb` as a high-speed data factory for Training Protein AI models. \n",
                "\n",
                "We leverage the `BatchedGenerator` to produce thousands of structures in milliseconds and feed them directly into **PyTorch** and **JAX** with **Zero-Copy** memory handover.\n",
                "\n",
                "### The Data Factory Workflow\n",
                "Traditional structural bio tools are optimized for single-file PDB processing. `synth-pdb` is optimized for **tensor throughput**.\n",
                "\n",
                "![Protein Data Factory Workflow](assets/workflow.png)\n",
                "\n",
                "### ‚ö†Ô∏è How to Run (Important!)\n",
                "This notebook requires a specific environment setup. Follow these steps strictly:\n",
                "\n",
                "1.  **Run All Cells** (`Runtime` -> `Run all` or `Ctrl+F9`).\n",
                "2.  **Wait for the Crash**: If on Colab, the setup cell will **automatically restart** the session to load libraries. This is normal.\n",
                "3.  **Local Users**: If you are running locally after editing the library code, **Restart your Kernel** manually to ensure changes take effect.\n",
                "4.  **Wait 10 Seconds**: Allow the session to reconnect.\n",
                "5.  **Run All Cells AGAIN**: This time, the setup will detect it is ready ('‚úÖ Dependencies Ready') and proceed typically."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "cellView": "form"
            },
            "outputs": [],
            "source": [
                "# @title Setup & Installation { display-mode: \"form\" }\n",
                "import os\n",
                "import sys\n",
                "from pathlib import Path\n",
                "\n",
                "# Ensure the local synth_pdb source code is prioritized if running from the repo\n",
                "try:\n",
                "    current_path = Path(\".\").resolve()\n",
                "    repo_root = current_path.parent.parent \n",
                "    if (repo_root / \"synth_pdb\").exists():\n",
                "        if str(repo_root) not in sys.path:\n",
                "            sys.path.insert(0, str(repo_root))\n",
                "            print(f\"üìå Added local library to path: {repo_root}\")\n",
                "except Exception:\n",
                "    pass\n",
                "\n",
                "if 'google.colab' in str(get_ipython()):\n",
                "    if not os.path.exists(\"installed.marker\"):\n",
                "        print(\"Running on Google Colab. Installing dependencies...\")\n",
                "        get_ipython().run_line_magic('pip', 'install synth-pdb py3Dmol')\n",
                "        \n",
                "        with open(\"installed.marker\", \"w\") as f:\n",
                "            f.write(\"done\")\n",
                "        \n",
                "        print(\"üîÑ Installation complete. KERNEL RESTARTING AUTOMATICALLY...\")\n",
                "        print(\"‚ö†Ô∏è Please wait 10 seconds, then Run All Cells again.\")\n",
                "        os.kill(os.getpid(), 9)\n",
                "    else:\n",
                "        print(\"‚úÖ Dependencies Ready.\")\n",
                "else:\n",
                "    import synth_pdb\n",
                "    print(f\"‚úÖ Running locally. Using synth-pdb version: {synth_pdb.__version__} from {synth_pdb.__file__}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "import time\n",
                "import matplotlib.pyplot as plt\n",
                "from synth_pdb.batch_generator import BatchedGenerator\n",
                "\n",
                "print(\"Libraries Loaded.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. High-Speed Generation\n",
                "We'll generate a batch of 1,000 peptides of length 50. In a traditional serial loop, this would take significant time. In `synth-pdb`, it's a single matrix operation."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Construct a clean sequence\n",
                "residues = [\"ALA\", \"GLY\", \"SER\", \"LEU\", \"VAL\", \"ILE\", \"MET\"] * 7\n",
                "sequence = \"-\".join(residues)\n",
                "n_batch = 1000\n",
                "\n",
                "generator = BatchedGenerator(sequence, n_batch=n_batch, full_atom=False)\n",
                "\n",
                "start = time.time()\n",
                "batch = generator.generate_batch(drift=5.0)\n",
                "print(f\"Generated {n_batch} structures.\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Benchmark: Serial vs. Batched Generation\n",
                "Why use `BatchedGenerator`? Below we compare the time to generate 1000 structures one-by-one vs. generating them in a single batch."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from synth_pdb.generator import generate_pdb_content\n",
                "\n",
                "def run_benchmark(n=100):\n",
                "    start_serial = time.time()\n",
                "    for _ in range(n):\n",
                "        _ = generate_pdb_content(sequence_str=sequence, minimize_energy=False)\n",
                "    serial_dt = time.time() - start_serial\n",
                "    \n",
                "    start_batched = time.time()\n",
                "    _ = generator.generate_batch(drift=1.0)\n",
                "    batched_dt = time.time() - start_batched\n",
                "    \n",
                "    return serial_dt, batched_dt\n",
                "\n",
                "n_test = 100\n",
                "s_time, b_time = run_benchmark(n_test)\n",
                "\n",
                "s_1k = s_time * (1000/n_test)\n",
                "b_1k = b_time * (1000/n_batch) if n_batch > 0 else b_time\n",
                "\n",
                "plt.figure(figsize=(8, 4))\n",
                "bars = plt.bar([\"Traditional Serial\", \"synth-pdb Batched\"], [s_1k, b_time], color=[\"#ff9999\", \"#667eea\"])\n",
                "plt.ylabel(\"Seconds per 1,000 Structures\")\n",
                "plt.title(f\"Real-World Performance Comparison\")\n",
                "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
                "\n",
                "for bar in bars:\n",
                "    yval = bar.get_height()\n",
                "    plt.text(bar.get_x() + bar.get_width()/2, yval + (s_1k*0.02), f\"{yval:.3f}s\", ha=\"center\", va=\"bottom\", fontweight=\"bold\")\n",
                "\n",
                "plt.show()\n",
                "\n",
                "print(f\"Vectorization Speedup: {s_1k / b_time:.1f}x\")\n",
                "print(f\"Theoretical throughput: {1000/b_time:.0f} structures/sec\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. PyTorch Handover (Zero-Copy)\n",
                "PyTorch can \"wrap\" a NumPy array without copying it. Any change to the NumPy array will be reflected in the Tensor (and vice versa)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "try:\n",
                "    import torch\n",
                "    \n",
                "    torch_tensor = torch.from_numpy(batch.coords).float()\n",
                "    \n",
                "    print(\"‚úÖ PyTorch Handover successful!\")\n",
                "    print(f\"Tensor Device: {torch_tensor.device}\")\n",
                "    print(f\"Contiguous in memory: {torch_tensor.is_contiguous()}\")\n",
                "except ImportError:\n",
                "    print(\"‚ùå PyTorch not found. Use 'pip install torch' to see this in action.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. JAX / MLX Handover\n",
                "JAX also supports efficient conversion from NumPy."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "try:\n",
                "    import jax.numpy as jnp\n",
                "    \n",
                "    jax_array = jnp.array(batch.coords)\n",
                "    print(\"‚úÖ JAX Handover successful!\")\n",
                "    print(f\"JAX Device: {jax_array.device}\")\n",
                "except ImportError:\n",
                "    print(\"‚ùå JAX not found.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Educational Note: Why does this matter?\n",
                "\n",
                "In deep learning for proteins, the **Data Loading** step is often the bottleneck. If your GPU has to wait for Python loops to calculate coordinates, it sits idle. \n",
                "\n",
                "By using `BatchedGenerator`, you can:\n",
                "1. Keep generation on the CPU/AMX units while the GPU trains.\n",
                "2. Avoid expensive serialized PDB parsing.\n",
                "3. Feed thousands of \"Hard Decoys\" (structures with noise) to help your model learn the energy landscape."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Visualizing the Data: Structural Ensembles\n",
                "In ML, we often want to train on \"Hard Decoys\"‚Äîstructures that are mostly correct but have physical noise. `BatchedGenerator` can produce these ensembles instantly."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.figure(figsize=(10, 6))\n",
                "for i in range(10):\n",
                "    plt.plot(batch.coords[i, :, 0], batch.coords[i, :, 1], alpha=0.3, label=f\"Model {i}\" if i==0 else \"\")\n",
                "\n",
                "plt.title(\"Ensemble Drift: Structural Noise for ML Training\")\n",
                "plt.xlabel(\"X (√Ö)\")\n",
                "plt.ylabel(\"Y (√Ö)\")\n",
                "plt.legend()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Interactive 3D Inspection\n",
                "Use `3Dmol.js` to inspect a sample structure from the batch."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "try:\n",
                "    import py3Dmol\n",
                "    import numpy as np\n",
                "    from synth_pdb.batch_generator import BatchedPeptide\n",
                "    \n",
                "    c = batch.coords[0].copy()\n",
                "    mask = np.any(c != 0, axis=1)\n",
                "    c_clean = c[mask]\n",
                "    \n",
                "    center = (c_clean.min(axis=0) + c_clean.max(axis=0)) / 2\n",
                "    c_centered = c_clean - center\n",
                "    \n",
                "    p = BatchedPeptide(\n",
                "        c_centered[np.newaxis, ...], \n",
                "        batch.sequence, \n",
                "        np.array(batch.atom_names)[mask].tolist(), \n",
                "        np.array(batch.residue_indices)[mask].tolist()\n",
                "    )\n",
                "    \n",
                "    view = py3Dmol.view(width=800, height=400)\n",
                "    view.setBackgroundColor(\"#fdfdfd\")\n",
                "    view.addModel(p.to_pdb(0), \"pdb\")\n",
                "    view.setStyle({\"stick\": {\"radius\": 0.15}, \"cartoon\": {\"color\": \"spectrum\"}})\n",
                "    \n",
                "    view.zoomTo()\n",
                "    view.center()\n",
                "    view.zoom(1.2)\n",
                "    view.show()\n",
                "    \n",
                "    print(f\"Viewer Ready. Visualizing {len(c_clean)} atoms.\")\n",
                "except ImportError:\n",
                "    print(\"py3Dmol not installed.\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.2"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}